{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator 可以使用 next 來進行循環中的一步\n",
    "文字上有點難解釋，直接來看範例就能了解什麼是 Generator!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 撰寫一個 Generator，一次吐出 list 中的一個值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_from_list_generator(your_list):\n",
    "    for i in your_list:\n",
    "        yield i "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = [1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = output_from_list_generator(my_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(next(gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(next(gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(next(gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(next(gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(next(gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(next(gen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 從上面的範例程式碼我們可以看到，當使用一次 next，generator 就會跑 for_loop 一次，因此得到 list 中的第一個值，當再使用一次後，for_loop 記得上次的循環，所以吐出第二個值。最後一次，因為 for loop 已經執行結束了，所以再使用 next 就會看到 StopIteration，無法在得到值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 我們可以撰寫一個無限循環的 Generator，只要使用 While True 即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inf_loop_generator(your_list):\n",
    "    while True:\n",
    "        for i in your_list:\n",
    "            yield i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = inf_loop_generator(my_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(next(gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(next(gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(next(gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(next(gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(next(gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(next(gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(next(gen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 上面的程式碼因為我們使用了 While True，所以 for loop 不會結束，只要 call next 就一定會跑一次循環，並返回值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 雖然 Cifar-10 的資料可以全部讀進記憶體，但讓我們試著用 Generator，批次的把 Cifar 10 的資料取出來，一次取 32 張出來！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_combine(img, ncols=8, size=1, path=False):\n",
    "    from math import ceil #往上進位至整數\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    nimg = len(img)\n",
    "    nrows = int(ceil(nimg/ncols))\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, sharex=True, sharey=True, figsize=(ncols*size,nrows*size))\n",
    "    if nrows == 0:\n",
    "        return\n",
    "    elif ncols == 1:\n",
    "        for r, ax in zip(np.arange(nrows), axes):\n",
    "            nth=r\n",
    "            if nth < nimg:\n",
    "                ax.imshow(img[nth], cmap='rainbow', vmin=0, vmax=1)\n",
    "                \n",
    "            ax.set_axis_off()\n",
    "    elif nrows == 1:\n",
    "        for c, ax in zip(np.arange(ncols), axes):\n",
    "            nth=c\n",
    "            if nth < nimg:\n",
    "                ax.imshow(img[nth], cmap='rainbow', vmin=0, vmax=1)\n",
    "            ax.set_axis_off()\n",
    "    else:\n",
    "        for r, row in zip(np.arange(nrows), axes):\n",
    "            for c, ax in zip(np.arange(ncols), row):\n",
    "                nth=r*ncols+c\n",
    "                if nth < nimg:\n",
    "                    ax.imshow(img[nth], cmap='rainbow', vmin=0, vmax=1)\n",
    "                ax.set_axis_off()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, x_test), (y_train, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cifar_generator(image_array, batch_size=32):\n",
    "    while True:\n",
    "        for indexs in range(0, len(image_array), batch_size):\n",
    "            images = x_train[indexs: indexs+batch_size]\n",
    "            labels = x_test[indexs: indexs+batch_size]\n",
    "            yield images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_gen = cifar_generator(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(cifar_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_combine(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(cifar_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_combine(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可以看到兩次的圖片並不一樣，這樣就可以開始訓練囉！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作業"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "請參考昨天的程式碼，將訓練資料讀取方式改寫成 Generator，並將原本的 model.fit 改為 model.fit_generator 來進行訓練。請參考 Keras [官方文件中 fit_generator 的說明](https://keras.io/models/sequential/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "batch_size = 128 # batch 的大小，如果出現 OOM error，請降低這個值\n",
    "num_classes = 10 # 類別的數量，Cifar 10 共有 10 個類別\n",
    "epochs = 10 # 訓練的 epochs 數量\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cifar_generator(image_array, batch_size=32):\n",
    "#     while True:\n",
    "#         for indexs in range(0, len(image_array), batch_size):\n",
    "#             images = x_train[indexs: indexs+batch_size]\n",
    "#             labels = x_test[indexs: indexs+batch_size]\n",
    "#             yield images, labels\n",
    "from sklearn.utils import shuffle\n",
    "def my_generator(x, y, batch_size):\n",
    "    while True:\n",
    "        for idx in range(0, len(x), batch_size): # 讓 idx 從 0 開始，一次增加 batch size。假設 batch_size=32, idx = 0, 32, 64, 96, ....\n",
    "            batch_x, batch_y = x[idx:idx+batch_size], y[idx:idx+batch_size]\n",
    "            yield batch_x, batch_y\n",
    "        x, y = shuffle(x, y) # loop 結束後，將資料順序打亂再重新循環\n",
    "train_generator = my_generator(x_train, y_train, batch_size) # 建立好我們寫好的 generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/10\n",
      "390/390 [==============================] - 10s 26ms/step - loss: 1.7427 - acc: 0.3705 - val_loss: 1.3547 - val_acc: 0.5104\n",
      "Epoch 2/10\n",
      "390/390 [==============================] - 7s 18ms/step - loss: 1.3367 - acc: 0.5261 - val_loss: 1.2981 - val_acc: 0.5445\n",
      "Epoch 3/10\n",
      "390/390 [==============================] - 7s 18ms/step - loss: 1.1353 - acc: 0.6009 - val_loss: 1.1837 - val_acc: 0.5915\n",
      "Epoch 4/10\n",
      "390/390 [==============================] - 7s 18ms/step - loss: 1.0053 - acc: 0.6473 - val_loss: 0.9389 - val_acc: 0.6698\n",
      "Epoch 5/10\n",
      "390/390 [==============================] - 7s 18ms/step - loss: 0.9053 - acc: 0.6840 - val_loss: 0.7877 - val_acc: 0.7250\n",
      "Epoch 6/10\n",
      "390/390 [==============================] - 7s 18ms/step - loss: 0.8406 - acc: 0.7063 - val_loss: 0.7843 - val_acc: 0.7229\n",
      "Epoch 7/10\n",
      "390/390 [==============================] - 7s 18ms/step - loss: 0.7806 - acc: 0.7276 - val_loss: 0.7506 - val_acc: 0.7399\n",
      "Epoch 8/10\n",
      "390/390 [==============================] - 7s 18ms/step - loss: 0.7359 - acc: 0.7453 - val_loss: 0.7003 - val_acc: 0.7614\n",
      "Epoch 9/10\n",
      "390/390 [==============================] - 7s 18ms/step - loss: 0.7003 - acc: 0.7566 - val_loss: 0.7119 - val_acc: 0.7582\n",
      "Epoch 10/10\n",
      "390/390 [==============================] - 7s 18ms/step - loss: 0.6735 - acc: 0.7657 - val_loss: 0.6999 - val_acc: 0.7618\n",
      "Test loss: 0.6999329203605652\n",
      "Test accuracy: 0.7618\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=int(len(x_train)/batch_size), # 一個 epochs 要執行幾次 update，通常是資料量除以 batch size\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[[[0.8352941 , 0.85490197, 0.88235295],\n",
      "         [0.8156863 , 0.84705883, 0.88235295],\n",
      "         [0.8117647 , 0.85882354, 0.8901961 ],\n",
      "         ...,\n",
      "         [0.79607844, 0.85490197, 0.8901961 ],\n",
      "         [0.81960785, 0.8627451 , 0.8784314 ],\n",
      "         [0.8156863 , 0.8509804 , 0.88235295]],\n",
      "\n",
      "        [[0.81960785, 0.8509804 , 0.88235295],\n",
      "         [0.8117647 , 0.8509804 , 0.8862745 ],\n",
      "         [0.8156863 , 0.85882354, 0.8980392 ],\n",
      "         ...,\n",
      "         [0.8901961 , 0.8980392 , 0.8862745 ],\n",
      "         [0.9254902 , 0.9254902 , 0.9019608 ],\n",
      "         [0.88235295, 0.88235295, 0.88235295]],\n",
      "\n",
      "        [[0.8666667 , 0.9019608 , 0.92941177],\n",
      "         [0.85490197, 0.8980392 , 0.93333334],\n",
      "         [0.84705883, 0.8901961 , 0.9137255 ],\n",
      "         ...,\n",
      "         [0.90588236, 0.8980392 , 0.8862745 ],\n",
      "         [0.9019608 , 0.8901961 , 0.88235295],\n",
      "         [0.8862745 , 0.88235295, 0.87058824]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.69411767, 0.69803923, 0.7058824 ],\n",
      "         [0.7019608 , 0.7058824 , 0.70980394],\n",
      "         [0.69411767, 0.69803923, 0.7058824 ],\n",
      "         ...,\n",
      "         [0.43137255, 0.45882353, 0.49411765],\n",
      "         [0.49019608, 0.5176471 , 0.5647059 ],\n",
      "         [0.5568628 , 0.5764706 , 0.61960787]],\n",
      "\n",
      "        [[0.6862745 , 0.69411767, 0.7019608 ],\n",
      "         [0.6901961 , 0.6901961 , 0.69803923],\n",
      "         [0.69411767, 0.69803923, 0.7058824 ],\n",
      "         ...,\n",
      "         [0.38039216, 0.4       , 0.42745098],\n",
      "         [0.4862745 , 0.49019608, 0.50980395],\n",
      "         [0.5411765 , 0.54509807, 0.56078434]],\n",
      "\n",
      "        [[0.6784314 , 0.6862745 , 0.6862745 ],\n",
      "         [0.6862745 , 0.69411767, 0.7019608 ],\n",
      "         [0.69411767, 0.69803923, 0.7058824 ],\n",
      "         ...,\n",
      "         [0.43137255, 0.4392157 , 0.44705883],\n",
      "         [0.56078434, 0.5568628 , 0.5529412 ],\n",
      "         [0.6745098 , 0.67058825, 0.6666667 ]]],\n",
      "\n",
      "\n",
      "       [[[0.15294118, 0.16470589, 0.08235294],\n",
      "         [0.16862746, 0.1764706 , 0.09803922],\n",
      "         [0.1764706 , 0.1882353 , 0.10980392],\n",
      "         ...,\n",
      "         [0.09803922, 0.09019608, 0.03921569],\n",
      "         [0.06666667, 0.05882353, 0.02352941],\n",
      "         [0.05490196, 0.03921569, 0.00784314]],\n",
      "\n",
      "        [[0.18039216, 0.19215687, 0.10980392],\n",
      "         [0.19215687, 0.20784314, 0.12156863],\n",
      "         [0.20392157, 0.21568628, 0.12941177],\n",
      "         ...,\n",
      "         [0.20392157, 0.20392157, 0.11372549],\n",
      "         [0.16470589, 0.16078432, 0.09019608],\n",
      "         [0.11764706, 0.11372549, 0.05882353]],\n",
      "\n",
      "        [[0.2       , 0.21568628, 0.1254902 ],\n",
      "         [0.21568628, 0.23137255, 0.14117648],\n",
      "         [0.22352941, 0.23921569, 0.14901961],\n",
      "         ...,\n",
      "         [0.24705882, 0.25490198, 0.14509805],\n",
      "         [0.23137255, 0.23921569, 0.13725491],\n",
      "         [0.21176471, 0.21568628, 0.1254902 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5686275 , 0.654902  , 0.60784316],\n",
      "         [0.5921569 , 0.6784314 , 0.6313726 ],\n",
      "         [0.62352943, 0.70980394, 0.6627451 ],\n",
      "         ...,\n",
      "         [0.7372549 , 0.84313726, 0.80784315],\n",
      "         [0.70980394, 0.8156863 , 0.78039217],\n",
      "         [0.6784314 , 0.78431374, 0.7490196 ]],\n",
      "\n",
      "        [[0.5803922 , 0.6666667 , 0.61960787],\n",
      "         [0.6       , 0.6862745 , 0.6392157 ],\n",
      "         [0.62352943, 0.7137255 , 0.6666667 ],\n",
      "         ...,\n",
      "         [0.73333335, 0.8392157 , 0.8039216 ],\n",
      "         [0.7058824 , 0.8117647 , 0.7764706 ],\n",
      "         [0.67058825, 0.7764706 , 0.74509805]],\n",
      "\n",
      "        [[0.56078434, 0.64705884, 0.6       ],\n",
      "         [0.5882353 , 0.67058825, 0.627451  ],\n",
      "         [0.60784316, 0.6901961 , 0.6431373 ],\n",
      "         ...,\n",
      "         [0.7058824 , 0.80784315, 0.77254903],\n",
      "         [0.6784314 , 0.78431374, 0.7490196 ],\n",
      "         [0.6431373 , 0.7490196 , 0.7176471 ]]],\n",
      "\n",
      "\n",
      "       [[[0.4745098 , 0.41568628, 0.42352942],\n",
      "         [0.5803922 , 0.5019608 , 0.50980395],\n",
      "         [0.7176471 , 0.63529414, 0.6431373 ],\n",
      "         ...,\n",
      "         [0.79607844, 0.7490196 , 0.7921569 ],\n",
      "         [0.8235294 , 0.7764706 , 0.8156863 ],\n",
      "         [0.85882354, 0.8156863 , 0.84313726]],\n",
      "\n",
      "        [[0.5254902 , 0.45490196, 0.46666667],\n",
      "         [0.5803922 , 0.5019608 , 0.5058824 ],\n",
      "         [0.7411765 , 0.65882355, 0.654902  ],\n",
      "         ...,\n",
      "         [0.8352941 , 0.7882353 , 0.8235294 ],\n",
      "         [0.85882354, 0.8117647 , 0.84705883],\n",
      "         [0.8784314 , 0.827451  , 0.85882354]],\n",
      "\n",
      "        [[0.5411765 , 0.46666667, 0.47058824],\n",
      "         [0.5372549 , 0.4627451 , 0.4627451 ],\n",
      "         [0.7019608 , 0.61960787, 0.6156863 ],\n",
      "         ...,\n",
      "         [0.8627451 , 0.8117647 , 0.8392157 ],\n",
      "         [0.8627451 , 0.8117647 , 0.84705883],\n",
      "         [0.85882354, 0.8039216 , 0.8392157 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.37254903, 0.30980393, 0.27450982],\n",
      "         [0.38039216, 0.30588236, 0.26666668],\n",
      "         [0.39215687, 0.30980393, 0.26666668],\n",
      "         ...,\n",
      "         [0.3137255 , 0.32941177, 0.30980393],\n",
      "         [0.29803923, 0.3137255 , 0.2901961 ],\n",
      "         [0.30980393, 0.32941177, 0.3019608 ]],\n",
      "\n",
      "        [[0.27450982, 0.23529412, 0.20784314],\n",
      "         [0.3372549 , 0.27450982, 0.23529412],\n",
      "         [0.3882353 , 0.30980393, 0.26666668],\n",
      "         ...,\n",
      "         [0.25490198, 0.27450982, 0.2627451 ],\n",
      "         [0.2784314 , 0.2901961 , 0.27058825],\n",
      "         [0.28235295, 0.3019608 , 0.27450982]],\n",
      "\n",
      "        [[0.16470589, 0.14509805, 0.1254902 ],\n",
      "         [0.22352941, 0.1764706 , 0.15294118],\n",
      "         [0.29411766, 0.23529412, 0.20392157],\n",
      "         ...,\n",
      "         [0.22745098, 0.2509804 , 0.2509804 ],\n",
      "         [0.27058825, 0.28627452, 0.26666668],\n",
      "         [0.28235295, 0.3019608 , 0.27450982]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[0.91764706, 0.9647059 , 0.96862745],\n",
      "         [0.92941177, 0.9647059 , 0.972549  ],\n",
      "         [0.94509804, 0.96862745, 0.98039216],\n",
      "         ...,\n",
      "         [0.75686276, 0.75686276, 0.7254902 ],\n",
      "         [0.78431374, 0.79607844, 0.77254903],\n",
      "         [0.83137256, 0.84313726, 0.8235294 ]],\n",
      "\n",
      "        [[0.9019608 , 0.9647059 , 0.9843137 ],\n",
      "         [0.9098039 , 0.9647059 , 0.9843137 ],\n",
      "         [0.92156863, 0.96862745, 0.99215686],\n",
      "         ...,\n",
      "         [0.9019608 , 0.9137255 , 0.89411765],\n",
      "         [0.93333334, 0.9372549 , 0.9254902 ],\n",
      "         [0.9607843 , 0.9607843 , 0.9529412 ]],\n",
      "\n",
      "        [[0.89411765, 0.9647059 , 0.99607843],\n",
      "         [0.8980392 , 0.9607843 , 0.99215686],\n",
      "         [0.90588236, 0.9607843 , 0.99215686],\n",
      "         ...,\n",
      "         [0.9372549 , 0.9372549 , 0.91764706],\n",
      "         [0.89411765, 0.8784314 , 0.85882354],\n",
      "         [0.8745098 , 0.8666667 , 0.8509804 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.8980392 , 0.90588236, 0.85882354],\n",
      "         [0.8862745 , 0.8980392 , 0.84705883],\n",
      "         [0.8862745 , 0.8980392 , 0.84705883],\n",
      "         ...,\n",
      "         [0.8980392 , 0.9098039 , 0.88235295],\n",
      "         [0.90588236, 0.91764706, 0.89411765],\n",
      "         [0.91764706, 0.93333334, 0.90588236]],\n",
      "\n",
      "        [[0.8862745 , 0.89411765, 0.8392157 ],\n",
      "         [0.8901961 , 0.8980392 , 0.84313726],\n",
      "         [0.9019608 , 0.9098039 , 0.85490197],\n",
      "         ...,\n",
      "         [0.8509804 , 0.87058824, 0.84313726],\n",
      "         [0.85882354, 0.8784314 , 0.8509804 ],\n",
      "         [0.8745098 , 0.8980392 , 0.87058824]],\n",
      "\n",
      "        [[0.8392157 , 0.8509804 , 0.8117647 ],\n",
      "         [0.84313726, 0.8509804 , 0.8156863 ],\n",
      "         [0.8627451 , 0.87058824, 0.83137256],\n",
      "         ...,\n",
      "         [0.8627451 , 0.88235295, 0.85490197],\n",
      "         [0.8627451 , 0.88235295, 0.85490197],\n",
      "         [0.87058824, 0.8901961 , 0.8666667 ]]],\n",
      "\n",
      "\n",
      "       [[[0.4862745 , 0.48235294, 0.48235294],\n",
      "         [0.41568628, 0.41960785, 0.4117647 ],\n",
      "         [0.6745098 , 0.6745098 , 0.6627451 ],\n",
      "         ...,\n",
      "         [0.16470589, 0.13333334, 0.12156863],\n",
      "         [0.18039216, 0.15686275, 0.1254902 ],\n",
      "         [0.13333334, 0.12941177, 0.10588235]],\n",
      "\n",
      "        [[0.53333336, 0.5176471 , 0.5372549 ],\n",
      "         [0.78039217, 0.7647059 , 0.78431374],\n",
      "         [0.9490196 , 0.9372549 , 0.9490196 ],\n",
      "         ...,\n",
      "         [0.24705882, 0.18039216, 0.20392157],\n",
      "         [0.18431373, 0.1254902 , 0.13333334],\n",
      "         [0.3019608 , 0.26666668, 0.2784314 ]],\n",
      "\n",
      "        [[0.59607846, 0.5921569 , 0.6392157 ],\n",
      "         [0.8392157 , 0.83137256, 0.8666667 ],\n",
      "         [0.9607843 , 0.9529412 , 0.9843137 ],\n",
      "         ...,\n",
      "         [0.42352942, 0.39607844, 0.43137255],\n",
      "         [0.21960784, 0.2       , 0.22352941],\n",
      "         [0.24313726, 0.23137255, 0.2509804 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.30588236, 0.30980393, 0.2901961 ],\n",
      "         [0.14509805, 0.15686275, 0.15294118],\n",
      "         [0.10980392, 0.1254902 , 0.13725491],\n",
      "         ...,\n",
      "         [0.7529412 , 0.7411765 , 0.7137255 ],\n",
      "         [0.75686276, 0.74509805, 0.7176471 ],\n",
      "         [0.7411765 , 0.7294118 , 0.7058824 ]],\n",
      "\n",
      "        [[0.6313726 , 0.63529414, 0.6117647 ],\n",
      "         [0.42352942, 0.43137255, 0.41960785],\n",
      "         [0.19607843, 0.20784314, 0.21176471],\n",
      "         ...,\n",
      "         [0.7529412 , 0.7411765 , 0.7137255 ],\n",
      "         [0.75686276, 0.74509805, 0.7176471 ],\n",
      "         [0.7372549 , 0.7294118 , 0.7058824 ]],\n",
      "\n",
      "        [[0.74509805, 0.74509805, 0.7254902 ],\n",
      "         [0.7490196 , 0.7529412 , 0.7372549 ],\n",
      "         [0.6156863 , 0.62352943, 0.6156863 ],\n",
      "         ...,\n",
      "         [0.7490196 , 0.7372549 , 0.70980394],\n",
      "         [0.7490196 , 0.73333335, 0.7058824 ],\n",
      "         [0.73333335, 0.72156864, 0.69803923]]],\n",
      "\n",
      "\n",
      "       [[[0.49803922, 0.4627451 , 0.3764706 ],\n",
      "         [0.5058824 , 0.47058824, 0.3647059 ],\n",
      "         [0.4862745 , 0.46666667, 0.3372549 ],\n",
      "         ...,\n",
      "         [0.62352943, 0.54901963, 0.3019608 ],\n",
      "         [0.61960787, 0.5568628 , 0.3137255 ],\n",
      "         [0.6156863 , 0.5529412 , 0.2901961 ]],\n",
      "\n",
      "        [[0.5921569 , 0.48235294, 0.34509805],\n",
      "         [0.5254902 , 0.33333334, 0.23921569],\n",
      "         [0.5019608 , 0.27450982, 0.20784314],\n",
      "         ...,\n",
      "         [0.5529412 , 0.50980395, 0.29803923],\n",
      "         [0.50980395, 0.47843137, 0.2627451 ],\n",
      "         [0.5686275 , 0.5372549 , 0.29803923]],\n",
      "\n",
      "        [[0.5254902 , 0.41568628, 0.32156864],\n",
      "         [0.40784314, 0.13725491, 0.10196079],\n",
      "         [0.39607844, 0.04313726, 0.10588235],\n",
      "         ...,\n",
      "         [0.56078434, 0.5294118 , 0.30588236],\n",
      "         [0.48235294, 0.4627451 , 0.24705882],\n",
      "         [0.5568628 , 0.5294118 , 0.3137255 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.67058825, 0.7058824 , 0.77254903],\n",
      "         [0.6666667 , 0.7019608 , 0.76862746],\n",
      "         [0.65882355, 0.69411767, 0.7607843 ],\n",
      "         ...,\n",
      "         [0.654902  , 0.69803923, 0.7490196 ],\n",
      "         [0.654902  , 0.7019608 , 0.74509805],\n",
      "         [0.65882355, 0.7058824 , 0.7529412 ]],\n",
      "\n",
      "        [[0.6509804 , 0.6901961 , 0.75686276],\n",
      "         [0.654902  , 0.6901961 , 0.75686276],\n",
      "         [0.6627451 , 0.69803923, 0.7647059 ],\n",
      "         ...,\n",
      "         [0.6509804 , 0.6862745 , 0.7372549 ],\n",
      "         [0.6509804 , 0.6901961 , 0.7372549 ],\n",
      "         [0.65882355, 0.69803923, 0.74509805]],\n",
      "\n",
      "        [[0.65882355, 0.69411767, 0.7607843 ],\n",
      "         [0.654902  , 0.6901961 , 0.75686276],\n",
      "         [0.654902  , 0.6901961 , 0.75686276],\n",
      "         ...,\n",
      "         [0.67058825, 0.7019608 , 0.75686276],\n",
      "         [0.65882355, 0.6901961 , 0.74509805],\n",
      "         [0.65882355, 0.6901961 , 0.74509805]]]], dtype=float32), array([[0., 0., 0., ..., 0., 1., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 1.],\n",
      "       [0., 1., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# print(np.asarray(next(train_generator)).shape())\n",
    "print(next(train_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
