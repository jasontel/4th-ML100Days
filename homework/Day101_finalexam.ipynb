{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作業\n",
    "礙於不是所有同學都有 GPU ，這邊的範例使用的是簡化版本的 ResNet，確保所有同學都能夠順利訓練!\n",
    "\n",
    "\n",
    "最後一天的作業請閱讀這篇非常詳盡的[文章](https://blog.gtwang.org/programming/keras-resnet-50-pre-trained-model-build-dogs-cats-image-classification-system/)，基本上已經涵蓋了所有訓練　CNN 常用的技巧，請使用所有學過的訓練技巧，盡可能地提高 Cifar-10 的 test data 準確率，截圖你最佳的結果並上傳來完成最後一次的作業吧!\n",
    "\n",
    "另外這些技巧在 Kaggle 上也會被許多人使用，更有人會開發一些新的技巧，例如使把預訓練在 ImageNet 上的模型當成 feature extractor 後，再拿擷取出的特徵重新訓練新的模型，這些技巧再進階的課程我們會在提到，有興趣的同學也可以[參考](https://www.kaggle.com/insaff/img-feature-extraction-with-pretrained-resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 2 classes.\n",
      "Found 0 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import *\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.models import load_model\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# 讀取資料集並作前處理\n",
    "# (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "# print('x_train shape:', x_train.shape)\n",
    "# print(x_train.shape[0], 'train samples')\n",
    "# print(x_test.shape[0], 'test samples')\n",
    "# x_train = x_train.astype('float32')\n",
    "# x_test = x_test.astype('float32')\n",
    "\n",
    "#standardize\n",
    "# x_train = x_train / 255.\n",
    "# x_test = x_test / 255.\n",
    "# y_train = to_categorical(y_train, 10)\n",
    "# y_test = to_categorical(y_test, 10)\n",
    "# 建立 ResNet 模型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./train\n",
      "Found 0 images belonging to 2 classes.\n",
      "Found 0 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_path = './train'\n",
    "test_path = './test'\n",
    "print(train_path)\n",
    "train_batches = ImageDataGenerator().flow_from_directory(train_path, target_size=(224,224), classes=['dogs', 'cats'], batch_size=10)\n",
    "test_batches = ImageDataGenerator().flow_from_directory(test_path, target_size=(224,224), classes=['dogs', 'cats'], batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet(input_shape=(32,32,3)) \n",
    "model.summary()\n",
    "batch_size = 256 # batch 的大小，如果出現 OOM error，請降低這個值\n",
    "num_classes = 10 # 類別的數量，Cifar 10 共有 10 個類別\n",
    "epochs = 100 # 訓練整個資料集共 30個循環\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "data_generator = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "data_aug = data_generator.flow(x_train,y_train,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/100\n",
      "195/195 [==============================] - 60s 310ms/step - loss: 2.1263 - acc: 0.4259 - val_loss: 1.9543 - val_acc: 0.4768\n",
      "Epoch 2/100\n",
      "195/195 [==============================] - 56s 288ms/step - loss: 1.7042 - acc: 0.5518 - val_loss: 1.9726 - val_acc: 0.4690\n",
      "Epoch 3/100\n",
      "195/195 [==============================] - 56s 288ms/step - loss: 1.4966 - acc: 0.6116 - val_loss: 2.3083 - val_acc: 0.4448\n",
      "Epoch 4/100\n",
      "195/195 [==============================] - 58s 295ms/step - loss: 1.3681 - acc: 0.6495 - val_loss: 1.6548 - val_acc: 0.5683\n",
      "Epoch 5/100\n",
      "195/195 [==============================] - 58s 295ms/step - loss: 1.2736 - acc: 0.6750 - val_loss: 1.4412 - val_acc: 0.6258\n",
      "Epoch 6/100\n",
      "195/195 [==============================] - 57s 292ms/step - loss: 1.1878 - acc: 0.7010 - val_loss: 1.6368 - val_acc: 0.6061\n",
      "Epoch 7/100\n",
      "195/195 [==============================] - 58s 296ms/step - loss: 1.1091 - acc: 0.7253 - val_loss: 1.2320 - val_acc: 0.6947\n",
      "Epoch 8/100\n",
      "195/195 [==============================] - 58s 296ms/step - loss: 1.0579 - acc: 0.7401 - val_loss: 1.3759 - val_acc: 0.6596\n",
      "Epoch 9/100\n",
      "195/195 [==============================] - 57s 294ms/step - loss: 1.0026 - acc: 0.7600 - val_loss: 1.1715 - val_acc: 0.7112\n",
      "Epoch 10/100\n",
      "195/195 [==============================] - 57s 292ms/step - loss: 0.9579 - acc: 0.7717 - val_loss: 2.1151 - val_acc: 0.5602\n",
      "Epoch 11/100\n",
      "195/195 [==============================] - 57s 294ms/step - loss: 0.9178 - acc: 0.7836 - val_loss: 1.7259 - val_acc: 0.5932\n",
      "Epoch 12/100\n",
      "195/195 [==============================] - 57s 294ms/step - loss: 0.8939 - acc: 0.7903 - val_loss: 1.5431 - val_acc: 0.6539\n",
      "Epoch 13/100\n",
      "195/195 [==============================] - 57s 293ms/step - loss: 0.8576 - acc: 0.8014 - val_loss: 1.0964 - val_acc: 0.7251\n",
      "Epoch 14/100\n",
      "195/195 [==============================] - 57s 292ms/step - loss: 0.8347 - acc: 0.8072 - val_loss: 1.0991 - val_acc: 0.7362\n",
      "Epoch 15/100\n",
      "195/195 [==============================] - 56s 287ms/step - loss: 0.8176 - acc: 0.8112 - val_loss: 1.1382 - val_acc: 0.7137\n",
      "Epoch 16/100\n",
      "195/195 [==============================] - 56s 287ms/step - loss: 0.7844 - acc: 0.8235 - val_loss: 1.1188 - val_acc: 0.7252\n",
      "Epoch 17/100\n",
      "195/195 [==============================] - 56s 287ms/step - loss: 0.7781 - acc: 0.8228 - val_loss: 1.1376 - val_acc: 0.7314\n",
      "Epoch 18/100\n",
      "195/195 [==============================] - 56s 287ms/step - loss: 0.7528 - acc: 0.8312 - val_loss: 1.0791 - val_acc: 0.7391\n",
      "Epoch 19/100\n",
      "195/195 [==============================] - 56s 287ms/step - loss: 0.7352 - acc: 0.8332 - val_loss: 1.1310 - val_acc: 0.7402\n",
      "Epoch 20/100\n",
      "195/195 [==============================] - 56s 287ms/step - loss: 0.7192 - acc: 0.8389 - val_loss: 1.0599 - val_acc: 0.7407\n",
      "Epoch 21/100\n",
      "195/195 [==============================] - 56s 288ms/step - loss: 0.7115 - acc: 0.8432 - val_loss: 1.0864 - val_acc: 0.7578\n",
      "Epoch 22/100\n",
      "195/195 [==============================] - 56s 287ms/step - loss: 0.6931 - acc: 0.8480 - val_loss: 1.4117 - val_acc: 0.7108\n",
      "Epoch 23/100\n",
      "195/195 [==============================] - 57s 290ms/step - loss: 0.6889 - acc: 0.8476 - val_loss: 0.8928 - val_acc: 0.7935\n",
      "Epoch 24/100\n",
      "195/195 [==============================] - 57s 291ms/step - loss: 0.6693 - acc: 0.8534 - val_loss: 0.8888 - val_acc: 0.8048\n",
      "Epoch 25/100\n",
      "195/195 [==============================] - 57s 291ms/step - loss: 0.6687 - acc: 0.8552 - val_loss: 1.2497 - val_acc: 0.7383\n",
      "Epoch 26/100\n",
      "195/195 [==============================] - 56s 287ms/step - loss: 0.6508 - acc: 0.8591 - val_loss: 0.8378 - val_acc: 0.8078\n",
      "Epoch 27/100\n",
      "195/195 [==============================] - 56s 287ms/step - loss: 0.6434 - acc: 0.8605 - val_loss: 0.9824 - val_acc: 0.7836\n",
      "Epoch 28/100\n",
      "195/195 [==============================] - 56s 287ms/step - loss: 0.6318 - acc: 0.8651 - val_loss: 1.2435 - val_acc: 0.7220\n",
      "Epoch 29/100\n",
      "195/195 [==============================] - 56s 287ms/step - loss: 0.6252 - acc: 0.8658 - val_loss: 0.8815 - val_acc: 0.7903\n",
      "Epoch 30/100\n",
      "195/195 [==============================] - 56s 288ms/step - loss: 0.6143 - acc: 0.8712 - val_loss: 0.9158 - val_acc: 0.7950\n",
      "Epoch 31/100\n",
      "195/195 [==============================] - 56s 286ms/step - loss: 0.6099 - acc: 0.8704 - val_loss: 0.8336 - val_acc: 0.8108\n",
      "Epoch 32/100\n",
      "195/195 [==============================] - 56s 289ms/step - loss: 0.6006 - acc: 0.8735 - val_loss: 0.9865 - val_acc: 0.7696\n",
      "Epoch 33/100\n",
      "195/195 [==============================] - 56s 287ms/step - loss: 0.5894 - acc: 0.8767 - val_loss: 1.0659 - val_acc: 0.7524\n",
      "Epoch 34/100\n",
      "195/195 [==============================] - 56s 289ms/step - loss: 0.5903 - acc: 0.8767 - val_loss: 0.7382 - val_acc: 0.8291\n",
      "Epoch 35/100\n",
      "195/195 [==============================] - 56s 288ms/step - loss: 0.5847 - acc: 0.8765 - val_loss: 0.7297 - val_acc: 0.8363\n",
      "Epoch 36/100\n",
      "195/195 [==============================] - 56s 288ms/step - loss: 0.5730 - acc: 0.8812 - val_loss: 0.9812 - val_acc: 0.7645\n",
      "Epoch 37/100\n",
      "195/195 [==============================] - 55s 282ms/step - loss: 0.5665 - acc: 0.8845 - val_loss: 0.8796 - val_acc: 0.7936\n",
      "Epoch 38/100\n",
      "195/195 [==============================] - 54s 279ms/step - loss: 0.5646 - acc: 0.8830 - val_loss: 0.9886 - val_acc: 0.7852\n",
      "Epoch 39/100\n",
      "195/195 [==============================] - 54s 278ms/step - loss: 0.5606 - acc: 0.8846 - val_loss: 1.4904 - val_acc: 0.7040\n",
      "Epoch 40/100\n",
      "195/195 [==============================] - 54s 277ms/step - loss: 0.5552 - acc: 0.8859 - val_loss: 0.8340 - val_acc: 0.8092\n",
      "Epoch 41/100\n",
      "195/195 [==============================] - 54s 279ms/step - loss: 0.5441 - acc: 0.8889 - val_loss: 1.2830 - val_acc: 0.7357\n",
      "Epoch 42/100\n",
      "195/195 [==============================] - 54s 277ms/step - loss: 0.5449 - acc: 0.8890 - val_loss: 0.7998 - val_acc: 0.8226\n",
      "Epoch 43/100\n",
      "195/195 [==============================] - 54s 278ms/step - loss: 0.5397 - acc: 0.8904 - val_loss: 0.7482 - val_acc: 0.8345\n",
      "Epoch 44/100\n",
      "195/195 [==============================] - 54s 277ms/step - loss: 0.5353 - acc: 0.8916 - val_loss: 0.8958 - val_acc: 0.8038\n",
      "Epoch 45/100\n",
      "195/195 [==============================] - 54s 277ms/step - loss: 0.5316 - acc: 0.8924 - val_loss: 0.7211 - val_acc: 0.8419\n",
      "Epoch 46/100\n",
      "195/195 [==============================] - 54s 277ms/step - loss: 0.5264 - acc: 0.8949 - val_loss: 0.8924 - val_acc: 0.8161\n",
      "Epoch 47/100\n",
      "195/195 [==============================] - 56s 286ms/step - loss: 0.5311 - acc: 0.8925 - val_loss: 0.7137 - val_acc: 0.8471\n",
      "Epoch 48/100\n",
      "195/195 [==============================] - 56s 288ms/step - loss: 0.5106 - acc: 0.8985 - val_loss: 0.8112 - val_acc: 0.8159\n",
      "Epoch 49/100\n",
      "195/195 [==============================] - 55s 283ms/step - loss: 0.5227 - acc: 0.8955 - val_loss: 0.7639 - val_acc: 0.8306\n",
      "Epoch 50/100\n",
      "195/195 [==============================] - 53s 273ms/step - loss: 0.5115 - acc: 0.8990 - val_loss: 0.8073 - val_acc: 0.8332\n",
      "Epoch 51/100\n",
      "195/195 [==============================] - 54s 276ms/step - loss: 0.5129 - acc: 0.8977 - val_loss: 0.9925 - val_acc: 0.7922\n",
      "Epoch 52/100\n",
      "195/195 [==============================] - 54s 279ms/step - loss: 0.5101 - acc: 0.8988 - val_loss: 0.8842 - val_acc: 0.8050\n",
      "Epoch 53/100\n",
      "195/195 [==============================] - 54s 278ms/step - loss: 0.5037 - acc: 0.9023 - val_loss: 0.8173 - val_acc: 0.8384\n",
      "Epoch 54/100\n",
      "195/195 [==============================] - 56s 288ms/step - loss: 0.4957 - acc: 0.9037 - val_loss: 0.8127 - val_acc: 0.8259\n",
      "Epoch 55/100\n",
      "195/195 [==============================] - 56s 287ms/step - loss: 0.4961 - acc: 0.9041 - val_loss: 0.8095 - val_acc: 0.8242\n",
      "Epoch 56/100\n",
      "195/195 [==============================] - 56s 286ms/step - loss: 0.5024 - acc: 0.9031 - val_loss: 0.9138 - val_acc: 0.8052\n",
      "Epoch 57/100\n",
      "195/195 [==============================] - 56s 287ms/step - loss: 0.4869 - acc: 0.9064 - val_loss: 0.7422 - val_acc: 0.8449\n",
      "Epoch 58/100\n",
      "195/195 [==============================] - 56s 286ms/step - loss: 0.4887 - acc: 0.9054 - val_loss: 0.8183 - val_acc: 0.8264\n",
      "Epoch 59/100\n",
      "195/195 [==============================] - 56s 288ms/step - loss: 0.4812 - acc: 0.9083 - val_loss: 0.8784 - val_acc: 0.8161\n",
      "Epoch 60/100\n",
      "195/195 [==============================] - 56s 287ms/step - loss: 0.4866 - acc: 0.9059 - val_loss: 0.7608 - val_acc: 0.8306\n",
      "Epoch 61/100\n",
      "195/195 [==============================] - 56s 286ms/step - loss: 0.4809 - acc: 0.9089 - val_loss: 0.8667 - val_acc: 0.8040\n",
      "Epoch 62/100\n",
      "195/195 [==============================] - 56s 286ms/step - loss: 0.4819 - acc: 0.9076 - val_loss: 0.9882 - val_acc: 0.7890\n",
      "Epoch 63/100\n",
      "195/195 [==============================] - 56s 286ms/step - loss: 0.4732 - acc: 0.9105 - val_loss: 0.8701 - val_acc: 0.8171\n",
      "Epoch 64/100\n",
      "195/195 [==============================] - 56s 286ms/step - loss: 0.4724 - acc: 0.9107 - val_loss: 0.7775 - val_acc: 0.8273\n",
      "Epoch 65/100\n",
      "195/195 [==============================] - 55s 285ms/step - loss: 0.4703 - acc: 0.9113 - val_loss: 0.8759 - val_acc: 0.8196\n",
      "Epoch 66/100\n",
      "195/195 [==============================] - 54s 275ms/step - loss: 0.4757 - acc: 0.9097 - val_loss: 0.7346 - val_acc: 0.8495\n",
      "Epoch 67/100\n",
      "195/195 [==============================] - 54s 276ms/step - loss: 0.4609 - acc: 0.9144 - val_loss: 0.7808 - val_acc: 0.8382\n",
      "Epoch 68/100\n",
      "195/195 [==============================] - 54s 276ms/step - loss: 0.4714 - acc: 0.9108 - val_loss: 0.7470 - val_acc: 0.8464\n",
      "Epoch 69/100\n",
      "195/195 [==============================] - 54s 276ms/step - loss: 0.4664 - acc: 0.9116 - val_loss: 1.0452 - val_acc: 0.7996\n",
      "Epoch 70/100\n",
      "195/195 [==============================] - 54s 277ms/step - loss: 0.4617 - acc: 0.9130 - val_loss: 0.6978 - val_acc: 0.8557\n",
      "Epoch 71/100\n",
      "195/195 [==============================] - 54s 276ms/step - loss: 0.4636 - acc: 0.9121 - val_loss: 0.8879 - val_acc: 0.8226\n",
      "Epoch 72/100\n",
      "195/195 [==============================] - 54s 276ms/step - loss: 0.4656 - acc: 0.9124 - val_loss: 0.6816 - val_acc: 0.8562\n",
      "Epoch 73/100\n",
      "195/195 [==============================] - 54s 276ms/step - loss: 0.4534 - acc: 0.9158 - val_loss: 0.9147 - val_acc: 0.8150\n",
      "Epoch 74/100\n",
      "195/195 [==============================] - 54s 277ms/step - loss: 0.4498 - acc: 0.9178 - val_loss: 0.7382 - val_acc: 0.8485\n",
      "Epoch 75/100\n",
      "195/195 [==============================] - 54s 276ms/step - loss: 0.4580 - acc: 0.9142 - val_loss: 0.6640 - val_acc: 0.8573\n",
      "Epoch 76/100\n",
      "195/195 [==============================] - 54s 277ms/step - loss: 0.4514 - acc: 0.9178 - val_loss: 0.6843 - val_acc: 0.8618\n",
      "Epoch 77/100\n",
      "195/195 [==============================] - 54s 276ms/step - loss: 0.4471 - acc: 0.9193 - val_loss: 0.7264 - val_acc: 0.8505\n",
      "Epoch 78/100\n",
      "195/195 [==============================] - 57s 292ms/step - loss: 0.4433 - acc: 0.9212 - val_loss: 1.1589 - val_acc: 0.7656\n",
      "Epoch 79/100\n",
      "195/195 [==============================] - 56s 290ms/step - loss: 0.4414 - acc: 0.9200 - val_loss: 0.6904 - val_acc: 0.8586\n",
      "Epoch 80/100\n",
      "195/195 [==============================] - 56s 288ms/step - loss: 0.4446 - acc: 0.9198 - val_loss: 1.0467 - val_acc: 0.7951\n",
      "Epoch 81/100\n",
      "195/195 [==============================] - 56s 287ms/step - loss: 0.4503 - acc: 0.9168 - val_loss: 0.8583 - val_acc: 0.8259\n",
      "Epoch 82/100\n",
      "195/195 [==============================] - 56s 286ms/step - loss: 0.4389 - acc: 0.9219 - val_loss: 0.8316 - val_acc: 0.8375\n",
      "Epoch 83/100\n",
      "195/195 [==============================] - 58s 296ms/step - loss: 0.4429 - acc: 0.9203 - val_loss: 1.1000 - val_acc: 0.7908\n",
      "Epoch 84/100\n",
      "195/195 [==============================] - 56s 287ms/step - loss: 0.4429 - acc: 0.9206 - val_loss: 0.9807 - val_acc: 0.8053\n",
      "Epoch 85/100\n",
      "195/195 [==============================] - 56s 287ms/step - loss: 0.4358 - acc: 0.9218 - val_loss: 0.7677 - val_acc: 0.8356\n",
      "Epoch 86/100\n",
      "195/195 [==============================] - 56s 287ms/step - loss: 0.4323 - acc: 0.9223 - val_loss: 0.6991 - val_acc: 0.8437\n",
      "Epoch 87/100\n",
      "195/195 [==============================] - 56s 287ms/step - loss: 0.4342 - acc: 0.9218 - val_loss: 0.8224 - val_acc: 0.8282\n",
      "Epoch 88/100\n",
      "195/195 [==============================] - 56s 287ms/step - loss: 0.4282 - acc: 0.9235 - val_loss: 0.7232 - val_acc: 0.8510\n",
      "Epoch 89/100\n",
      "195/195 [==============================] - 56s 287ms/step - loss: 0.4338 - acc: 0.9214 - val_loss: 0.6881 - val_acc: 0.8580\n",
      "Epoch 90/100\n",
      "195/195 [==============================] - 56s 288ms/step - loss: 0.4297 - acc: 0.9237 - val_loss: 0.9125 - val_acc: 0.8252\n",
      "Epoch 91/100\n",
      "195/195 [==============================] - 56s 286ms/step - loss: 0.4324 - acc: 0.9234 - val_loss: 0.6979 - val_acc: 0.8556\n",
      "Epoch 92/100\n",
      "195/195 [==============================] - 57s 294ms/step - loss: 0.4281 - acc: 0.9249 - val_loss: 0.7085 - val_acc: 0.8565\n",
      "Epoch 93/100\n",
      "195/195 [==============================] - 56s 289ms/step - loss: 0.4297 - acc: 0.9224 - val_loss: 0.7401 - val_acc: 0.8499\n",
      "Epoch 94/100\n",
      "195/195 [==============================] - 56s 288ms/step - loss: 0.4257 - acc: 0.9259 - val_loss: 0.6799 - val_acc: 0.8601\n",
      "Epoch 95/100\n",
      "195/195 [==============================] - 56s 286ms/step - loss: 0.4235 - acc: 0.9255 - val_loss: 0.8140 - val_acc: 0.8254\n",
      "Epoch 96/100\n",
      "195/195 [==============================] - 56s 288ms/step - loss: 0.4266 - acc: 0.9248 - val_loss: 0.7449 - val_acc: 0.8497\n",
      "Epoch 97/100\n",
      "195/195 [==============================] - 56s 287ms/step - loss: 0.4174 - acc: 0.9291 - val_loss: 0.8082 - val_acc: 0.8397\n",
      "Epoch 98/100\n",
      "195/195 [==============================] - 56s 286ms/step - loss: 0.4227 - acc: 0.9255 - val_loss: 0.7149 - val_acc: 0.8514\n",
      "Epoch 99/100\n",
      "195/195 [==============================] - 56s 286ms/step - loss: 0.4245 - acc: 0.9244 - val_loss: 0.8032 - val_acc: 0.8270\n",
      "Epoch 100/100\n",
      "195/195 [==============================] - 56s 287ms/step - loss: 0.4204 - acc: 0.9277 - val_loss: 0.7409 - val_acc: 0.8433\n",
      "Test loss: 0.7408840316772461\n",
      "Test accuracy: 0.8433\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(data_aug,\n",
    "                                steps_per_epoch=int(len(x_train)/batch_size), # 一個 epochs 要執行幾次 update，通常是資料量除以 batch size\n",
    "                                epochs=epochs,\n",
    "                                verbose=1,\n",
    "                                validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 326)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "img = Image.open('0a3e7507742e246b3a2e630debbbaf99.jpg')\n",
    "print(img.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
